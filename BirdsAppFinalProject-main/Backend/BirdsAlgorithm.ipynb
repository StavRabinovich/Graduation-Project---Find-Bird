{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voxFSjjMm0YR"
      },
      "source": [
        "# **Birds Recognition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7cTtT_2m3gI"
      },
      "source": [
        "## **Import and Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8a2OiZAm46w",
        "outputId": "70342c6d-11c4-4bd3-a288-a951e61ffdb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-15 23:18:45.462824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-07-15 23:18:45.462867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version=  2.9.1\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import  cv2\n",
        "from    cv2 import imread\n",
        "from scipy.signal import  convolve2d\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from   torchvision import datasets, models, transforms\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "print('Tensorflow version= ',tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81-X9OQPm5UD"
      },
      "source": [
        "## **Printing Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l9TlJHRunBJo"
      },
      "outputs": [],
      "source": [
        "# Printing images from directory\n",
        "def print_images_from_dir(dir, img_num = 15, rows = 3, cols = 5):\n",
        "    dir = dir + '/'\n",
        "    dirnames = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 4*rows))\n",
        "    \n",
        "    for j,i in enumerate(dirnames[:img_num]):\n",
        "        ax = axes[j//cols, j%cols]\n",
        "        file = dir + i + '/'+ os.listdir(dir+i)[0]\n",
        "        image = mpimg.imread(file)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title('Label: {}'.format(i))\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdZM92vcm5Rn"
      },
      "source": [
        "## **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tsod7L0TnpIQ"
      },
      "outputs": [],
      "source": [
        "# PATH = '../../../d/Images/nabirds/'\n",
        "PATH = '../../../d/Images/nabirds/'\n",
        "\n",
        "PATH_TRAIN = PATH + 'Train/'\n",
        "PATH_TEST = PATH + 'Test/'\n",
        "PATH_VAL = PATH + 'Validation/'\n",
        "\n",
        "IMGS_PATH = '../../../d/Images/nabirds/images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jB98HQCQnr4X"
      },
      "outputs": [],
      "source": [
        "# path_imgs = 'D:/Images/nabirds/images/'\n",
        "# birds_DB = ['House_Sparrow', 'American_Pipit', 'Gadwall', 'European_Goldfinch','Horned_Grebe']\n",
        "\n",
        "birds_DB = ['0857','0527','1005', '0525', '0315', '0796']\n",
        "birds_names_DB = ['American Pipit', 'Eurasian Collared-Dove', 'House Sparrow', 'European Starling', 'Gadwall', 'Rock Pigeon']\n",
        "# 440 American Pipit\n",
        "# 857 American Pipit\n",
        "# 527 Eurasian Collared-Dove\n",
        "# 1005 European Starling (Juvenile)\n",
        "# 525 Rock Pigeon\n",
        "# 315 Gadwall (Breeding male)\n",
        "# 445 House Sparrow 796\n",
        "\n",
        "# TODO : Change Numbers to names\n",
        "def create_listdir(imgs): # Fixes the '._' bug\n",
        "  dir_lst = []\n",
        "  for dir in os.listdir(imgs):\n",
        "    if dir[:2] == '._':\n",
        "      dir_lst.append(dir[2:])\n",
        "    else:\n",
        "      dir_lst.append(dir)\n",
        "  return dir_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['American Pipit', 'Eurasian Collared-Dove', 'House Sparrow', 'European Starling', 'Gadwall', 'Rock Pigeon'])\n"
          ]
        }
      ],
      "source": [
        "bird_dict = { \n",
        "    'American Pipit': ['0440','0857'],\n",
        "    'Eurasian Collared-Dove' : ['0105', '0527'] , \n",
        "    'House Sparrow': ['0445', '0796', '1003'],\n",
        "    'European Starling' : ['0439', '0748', '0856', '1005'],\n",
        "    'Gadwall' : ['0315','0614', '0037'], \n",
        "    'Rock Pigeon' : ['0525', '0045'],\n",
        "}\n",
        "print(bird_dict.keys())\n",
        "# def rename_folders(birds_DB, bird_dict):\n",
        "#   for num in birds_DB:\n",
        "#     b_name = ''\n",
        "#     for key in bird_dict.keys():\n",
        "#       if num in bird_dict.get(key): \n",
        "#         print(f'{num} is {key}')\n",
        "#         b_name = key\n",
        "#         brds = 'nabirds'\n",
        "#         os.rename(f'D:\\Images\\{brds}\\images\\{num}', f'D:\\Images\\{brds}\\images\\{b_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename_folders(birds_DB, bird_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ewdgfqnyAI",
        "outputId": "12a93bbf-78de-4bf4-8017-ecc3de520705"
      },
      "outputs": [],
      "source": [
        "# def create_folders(b_name):\n",
        "#   paths = [PATH_TRAIN, PATH_TEST, PATH_VAL]\n",
        "#   n_paths = []\n",
        "#   for pth in paths:\n",
        "#     pt = pth + b_name + '/'\n",
        "#     n_paths.append(pt)\n",
        "#     os.mkdir(pt)\n",
        "#   return n_paths\n",
        "# size = (224,224)\n",
        "\n",
        "# def name_folders(bird):\n",
        "#   paths = [PATH_TRAIN, PATH_TEST, PATH_VAL]\n",
        "#   n_paths = []\n",
        "#   for pth in paths:\n",
        "#     pt = pth + bird + '/'\n",
        "#     n_paths.append(pt)\n",
        "#   return n_paths\n",
        "\n",
        "# def create_data(path, birds_list=birds_names_DB):\n",
        "#   my_imgs = []\n",
        "#   count_imgs = 0 # Counts all images\n",
        "#   for dir in create_listdir(path):\n",
        "#     dir_count=0 # Counts every dir's images\n",
        "#     if dir in birds_list:\n",
        "#         current_path = path + '/' + dir\n",
        "#         print(f'Reads from: {dir}')\n",
        "#         # cpth = create_listdir(current_path)\n",
        "#         # n_pths = create_folders(dir)\n",
        "#         n_pths = name_folders(dir)\n",
        "#         # print(os.listdir(current_path))\n",
        "#         # for image in create_listdir(current_path): \n",
        "#         for image in os.listdir(current_path): \n",
        "#           c_path = current_path + '/' + image # current image path\n",
        "#           c_image = cv2.imread(c_path)#, cv2.COLOR_BGR2RGB)\n",
        "#           c_image = cv2.resize(c_image, size)\n",
        "#           my_imgs.append([c_path, dir, '']) # tupple with (img dir, target)\n",
        "#           dir_count += 1 \n",
        "\n",
        "#         train_imgs = int(dir_count * 0.7)\n",
        "#         test_imgs = int(dir_count * 0.2)\n",
        "#         # print(f'num of train: {train_imgs} \\nNum of test: {test_imgs}\\nNum of val: \\nDIR_COUNT: {dir_count}')\n",
        "        \n",
        "#         for i, img in enumerate(os.listdir(current_path)):\n",
        "#           c_path = current_path + '/' + img # current image path\n",
        "#           if i <= train_imgs:\n",
        "#             my_imgs[count_imgs + i][2] = 'train'\n",
        "#             shutil.copy2(c_path, n_pths[0])\n",
        "#           elif i <= train_imgs + test_imgs:\n",
        "#             my_imgs[count_imgs + i][2] = 'test'\n",
        "#             shutil.copy2(c_path,  n_pths[1])\n",
        "#           else: \n",
        "#             my_imgs[count_imgs + i][2] = 'valid'\n",
        "#             shutil.copy2(c_path,  n_pths[2])\n",
        "#         count_imgs += dir_count\n",
        "        \n",
        "#   return my_imgs, count_imgs\n",
        "\n",
        "\n",
        "# def data_to_csv(path, birds_list=birds_names_DB):\n",
        "#   my_imgs, count_imgs = create_data(path, birds_list)\n",
        "#   df = pd.DataFrame(data=my_imgs, columns=['path','name','dataset'])\n",
        "#   df.to_csv()\n",
        "#   return df\n",
        "\n",
        "# my_df = data_to_csv(path_imgs) ## Create csv of file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Augmentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helping matrixes\n",
        "sobelX = np.asarray(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]), dtype=np.float32) * 1/16\n",
        "sobelY = np.asarray(([-1,-2,-1], [0, 0, 0], [1, 2, 1]), dtype=np.float32) * 1/16\n",
        "laplacian = np.array(([0, -1, 0], [-1, 5, -1], [0, -1, 0]), dtype='int') * 0.25 \n",
        "\n",
        "mats = [sobelX, sobelY, laplacian]\n",
        "\n",
        "# Calculates padding\n",
        "def calculate_padding_single_dim(dim_in, dim_out, kernel_size):\n",
        "    return  int(np.ceil((dim_out - dim_in + kernel_size) /2 ) -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Sharping\n",
        "def sharp_img(img, kernel=laplacian):\n",
        "  for i in range(img.shape[-1]):\n",
        "    sharpened_img = convolve2d(img[:, :, i], kernel) # img convolation with matrix\n",
        "  return np.abs(sharpened_img) # values are positive\n",
        "\n",
        "## Rotate\n",
        "def rotate(img: np.ndarray, angle: int):\n",
        "  h, w = img.shape[0], img.shape[1]\n",
        "  res_img = np.zeros(img.shape) # New image creation\n",
        "  # Angle's calculations\n",
        "  angle = np.deg2rad(angle)\n",
        "  cos_a = np.cos(angle)\n",
        "  sin_a = np.sin(angle)\n",
        "  # Image's center\n",
        "  midY = round(((h + 1) / 2) - 1)\n",
        "  midX = round(((w + 1) / 2) - 1)\n",
        "  # Result's center\n",
        "  yCenter = round((midY * cos_a) - (midX * sin_a))\n",
        "  xCenter = round((midY * sin_a) + (midX * cos_a))\n",
        "\n",
        "  for y in range(h):\n",
        "    for x in range(w):\n",
        "      nX = round((y * sin_a) + (x * cos_a)) - xCenter + midX\n",
        "      nY = round((y * cos_a) - (x * sin_a)) - yCenter + midY\n",
        "      if (w > nX and (nX > 0)) and (h > nY and (nY > 0)):\n",
        "        res_img[nY ,nX] = img[y ,x]\n",
        "  \n",
        "  return res_img.astype(np.uint8)\n",
        "\n",
        "## Horizontal Flip\n",
        "def horizontal_flip(img):\n",
        "  f_img = img[:, ::-1]\n",
        "  return f_img\n",
        "\n",
        "\n",
        "angles = [-20, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def img_augmentation(img_name, path_dir):\n",
        "    added_imgs = []\n",
        "    for i in range(6):\n",
        "        img = np.array(Image.open(f'{path_dir}/{img_name}'))\n",
        "        rnd = random.randint(0, 11)\n",
        "        if (rnd // 2 == 0):\n",
        "            n_img = sharp_img(img,kernel=mats[random.randint(0,len(mats)-1)])\n",
        "        else:\n",
        "            n_img = img\n",
        "        if (rnd // 3 == 0):\n",
        "            n_img = rotate(n_img, angle=random.randint(angles[0], angles[1]))\n",
        "        if (rnd // 5 == 0):\n",
        "            n_img = horizontal_flip(n_img)\n",
        "        added_imgs.append(n_img)\n",
        "\n",
        "    return added_imgs\n",
        "\n",
        "def dir_augments(path_dir):\n",
        "    added_imgs = []\n",
        "    for img in os.listdir(path_dir):\n",
        "        added_imgs = added_imgs + img_augmentation(img,path_dir)\n",
        "    count = 0\n",
        "    for img in added_imgs:\n",
        "        im = Image.fromarray(img)\n",
        "        im.save(f'{path_dir}/aug_{count}.jpg')\n",
        "        count += 1     \n",
        "\n",
        "def augmentations():\n",
        "    for pth in [PATH_TRAIN, PATH_TEST, PATH_VAL]:\n",
        "        print('doit')\n",
        "        for bird_dir in os.listdir(pth):\n",
        "            print(f'path = {bird_dir}')\n",
        "            dir_augments(f'{pth}/{bird_dir}/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reads from: American Pipit\n",
            "Reads from: Eurasian Collared-Dove\n",
            "Reads from: European Starling\n",
            "Reads from: Gadwall\n",
            "Reads from: House Sparrow\n",
            "Reads from: Rock Pigeon\n"
          ]
        }
      ],
      "source": [
        "def create_folders(b_name):\n",
        "  paths = [PATH_TRAIN, PATH_TEST, PATH_VAL]\n",
        "  n_paths = []\n",
        "  for pth in paths:\n",
        "    pt = pth + b_name + '/'\n",
        "    n_paths.append(pt)\n",
        "    if not os.path.exists(pt):\n",
        "      os.mkdir(pt)\n",
        "  return n_paths\n",
        "size = (224,224)\n",
        "\n",
        "def name_folders(bird):\n",
        "  paths = [PATH_TRAIN, PATH_TEST, PATH_VAL]\n",
        "  n_paths = []\n",
        "  for pth in paths:\n",
        "    pt = pth + bird + '/'\n",
        "    n_paths.append(pt)\n",
        "  return n_paths\n",
        "\n",
        "def create_data(path, birds_list=birds_names_DB):\n",
        "  my_imgs = []\n",
        "  count_imgs = 0 # Counts all images\n",
        "  for dir in create_listdir(path):\n",
        "    dir_count=0 # Counts every dir's images\n",
        "    if dir in birds_list:\n",
        "        current_path = path + '/' + dir\n",
        "        print(f'Reads from: {dir}')\n",
        "        # cpth = create_listdir(current_path)\n",
        "        n_pths = create_folders(dir)\n",
        "        # n_pths = name_folders(dir)\n",
        "        # print(os.listdir(current_path))\n",
        "        # for image in create_listdir(current_path): \n",
        "        for image in os.listdir(current_path): \n",
        "          c_path = current_path + '/' + image # current image path\n",
        "          c_image = cv2.imread(c_path)#, cv2.COLOR_BGR2RGB)\n",
        "          c_image = cv2.resize(c_image, size)\n",
        "          my_imgs.append([c_path, dir, '']) # tupple with (img dir, target)\n",
        "          dir_count += 1 \n",
        "\n",
        "        train_imgs = int(dir_count * 0.7)\n",
        "        test_imgs = int(dir_count * 0.2)\n",
        "        # print(f'num of train: {train_imgs} \\nNum of test: {test_imgs}\\nNum of val: \\nDIR_COUNT: {dir_count}')\n",
        "\n",
        "        for i, img in enumerate(os.listdir(current_path)):\n",
        "          c_path = current_path + '/' + img # current image path\n",
        "          if i <= train_imgs:\n",
        "            my_imgs[count_imgs + i][2] = 'train'\n",
        "            shutil.copy2(c_path, n_pths[0])\n",
        "          elif i <= train_imgs + test_imgs:\n",
        "            my_imgs[count_imgs + i][2] = 'test'\n",
        "            shutil.copy2(c_path,  n_pths[1])\n",
        "          else: \n",
        "            my_imgs[count_imgs + i][2] = 'valid'\n",
        "            shutil.copy2(c_path,  n_pths[2])\n",
        "        count_imgs += dir_count\n",
        "        \n",
        "  return my_imgs, count_imgs\n",
        "\n",
        "def data_to_csv(path, birds_list=birds_names_DB):\n",
        "  my_imgs, count_imgs = create_data(path, birds_list)\n",
        "  df = pd.DataFrame(data=my_imgs, columns=['path','name','dataset'])\n",
        "  df.to_csv()\n",
        "  return df\n",
        "\n",
        "my_df = data_to_csv(IMGS_PATH) ## Create csv of file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# augmentations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BKprfk-wnyCY"
      },
      "outputs": [],
      "source": [
        "# }train_path = []\n",
        "test_path = []\n",
        "train_df = my_df.query(\"dataset == 'train'\")\n",
        "test_df = my_df.query(\"dataset == 'test'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQgKqWqPm5KZ"
      },
      "source": [
        "### **Choosing our birds**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVuLuCprm5H6"
      },
      "source": [
        "## **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vvjRvVD9GrkQ"
      },
      "outputs": [],
      "source": [
        "df_train = my_df.query(\"dataset == 'train' \")\n",
        "del df_train['dataset']\n",
        "\n",
        "df_test = my_df.query(\"dataset == 'test' \")\n",
        "del df_test['dataset']\n",
        "\n",
        "df_valid = my_df.query(\"dataset == 'valid' \")\n",
        "del df_valid['dataset']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yBOfnTj1Nqwd"
      },
      "outputs": [],
      "source": [
        "# def create_directory(dir_name, df, birds_list=birds_DB):\n",
        "#   drive.mount(dir_name)\n",
        "#   for bird in birds_list:\n",
        "#     pth = dir_name + '/' + bird + '/'\n",
        "#     drive.mount(pth)\n",
        "#     # TODO: Upload files\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dfn59rpF3Qd",
        "outputId": "8f79bbd7-ae72-4298-a014-28dbbdec20f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3192 images belonging to 6 classes.\n",
            "Found 889 images belonging to 6 classes.\n",
            "Found 448 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation for training using ImageDataGenerator \n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Training data\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "train_generator = train_datagen.flow_from_directory(PATH_TRAIN, target_size=(224,224),\n",
        "                                                    batch_size= 30, class_mode='categorical')\n",
        "\n",
        "# Test data\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "test_generator = test_datagen.flow_from_directory(PATH_TEST, target_size=(224,224),\n",
        "                                                    batch_size= 30, class_mode='categorical')\n",
        "\n",
        "# Validation data\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
        "valid_generator = valid_datagen.flow_from_directory(PATH_VAL, target_size=(224,224),\n",
        "                                                    batch_size= 30, class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayy_uD34m5GY"
      },
      "source": [
        "## **Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJu01qk1F9dY"
      },
      "source": [
        "### Densenet model definition, training, evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFooZFiTF9Hm",
        "outputId": "e4d8b1be-bf77-4aa3-81be-b2e03d101d17"
      },
      "outputs": [],
      "source": [
        "# densenet201_raw_model = tf.keras.applications.densenet.DenseNet201(include_top=False,\n",
        "#                                                                 weights='imagenet',\n",
        "#                                                                 input_shape=(224,224,3), # input size of the images(fixed)\n",
        "#                                                                 pooling='max')\n",
        "\n",
        "# # To not train these weights with our training images\n",
        "# for layers in densenet201_raw_model.layers:\n",
        "#     layers.trainable=False\n",
        "\n",
        "# # append Dense layers to clssify it for number of classes for the given problem\n",
        "# num_of_classes = len(birds_DB)\n",
        "# densenet201_model_output = densenet201_raw_model.layers[-1].output\n",
        "# appended_layer = tf.keras.layers.Flatten()(densenet201_model_output)\n",
        "# appended_layer = tf.keras.layers.Dense(num_of_classes, activation='softmax')(appended_layer)\n",
        "\n",
        "\n",
        "# # final model\n",
        "# densenet201_final_model = tf.keras.Model(densenet201_raw_model.input, appended_layer)\n",
        "# print(densenet201_final_model.summary())\n",
        "# densenet201_final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpY-wpIIMPPM",
        "outputId": "7316169b-77ca-4371-e861-8b5f98bd6a4f"
      },
      "outputs": [],
      "source": [
        "# history = densenet201_final_model.fit(\n",
        "#                                     train_generator,\n",
        "#                                     epochs=150,\n",
        "#                                     validation_data=valid_generator)\n",
        "\n",
        "# try:\n",
        "#     # vgg_model.save_model('./weights/vgg')\n",
        "#     tf.keras.models.save_model(densenet201_final_model,filepath='./weights/denseNet')\n",
        "# except Exception as e:\n",
        "#     print(f'Failed to save weights')\n",
        "#     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwlK-5Jnm4hT",
        "outputId": "1dc8ae50-26e2-49a9-f9fb-667941b69bc6"
      },
      "outputs": [],
      "source": [
        "# densenet201_final_model.evaluate(test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "hdiswfwobCDU",
        "outputId": "ffcfbe85-c8d8-4643-e985-a76acaf0c221"
      },
      "outputs": [],
      "source": [
        "# def plot_loss_curves_densenet(history):\n",
        "    \n",
        "#     '''\n",
        "#       returns seperate loss curves for training and validation metrics\n",
        "#     '''\n",
        "#     train_loss=history.history['loss']\n",
        "#     val_loss=history.history['val_loss']\n",
        "\n",
        "#     train_accuracy=history.history['accuracy']\n",
        "#     val_accuracy=history.history['val_accuracy']\n",
        "\n",
        "#     epochs=range(1,len(history.history['loss'])+1)\n",
        "#     plt.figure(figsize=(20,7))\n",
        "#   # plot loss data\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.plot(epochs,train_loss,label=\"training_loss\")\n",
        "#     plt.plot(epochs,val_loss,label=\"validation_loss\")\n",
        "#     plt.title(\"Loss curves\")\n",
        "#     plt.xlabel('epochs')\n",
        "#     plt.ylabel('loss')\n",
        "#     plt.legend()\n",
        "#   # plt.show()\n",
        "\n",
        "#   # plot accuracy data\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.plot(epochs,train_accuracy,label=\"training_acc\")\n",
        "#     plt.plot(epochs,val_accuracy,label=\"validation_acc\")\n",
        "#     plt.title(\"Accuracy curves\")\n",
        "#     plt.xlabel('epochs')\n",
        "#     plt.ylabel('Accuracy')\n",
        "#     plt.legend()\n",
        "\n",
        "# plot_loss_curves_densenet(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-15 23:19:14.432817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-07-15 23:19:14.434406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434445: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitrlior/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2022-07-15 23:19:14.434604: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-07-15 23:19:14.435000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 224)               5619936   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 224)               50400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1350      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,386,374\n",
            "Trainable params: 5,671,686\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224 ,224 , 3))\n",
        "#eff_model.summary()\n",
        "vgg_model.trainable = False\n",
        "\n",
        "layer0 = keras.layers.Flatten(name='flatten')(vgg_model.output)\n",
        "layer1 = keras.layers.Dense(224, activation='relu',name='fc1')(layer0)\n",
        "layer2 = keras.layers.Dense(224, activation='relu',name='fc2')(layer1)\n",
        "out_layer = keras.layers.Dense(6, activation='softmax')(layer2)\n",
        "vgg_model = keras.Model(vgg_model.input, out_layer)\n",
        "vgg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "107/107 [==============================] - 316s 3s/step - loss: 0.9848 - accuracy: 0.6629 - val_loss: 1.1693 - val_accuracy: 0.5871\n",
            "Epoch 2/50\n",
            "107/107 [==============================] - 314s 3s/step - loss: 0.3270 - accuracy: 0.8850 - val_loss: 1.4630 - val_accuracy: 0.5603\n",
            "Epoch 3/50\n",
            "107/107 [==============================] - 311s 3s/step - loss: 0.2770 - accuracy: 0.8994 - val_loss: 1.7909 - val_accuracy: 0.4955\n",
            "Epoch 4/50\n",
            "107/107 [==============================] - 309s 3s/step - loss: 0.2372 - accuracy: 0.9076 - val_loss: 1.5675 - val_accuracy: 0.5647\n"
          ]
        }
      ],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "vgg_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'], )\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "            #   ,\n",
        "            #   ModelCheckpoint(filepath=\"./weights/vgg.{epoch:02d}-{acc:.2f}.h5\", monitor='val_acc', save_best_only=False, mode='max')\n",
        "            ]\n",
        "\n",
        "history_vgg = vgg_model.fit(\n",
        "    train_generator, \n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg/assets\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # vgg_model.save_model('./weights/vgg')\n",
        "    tf.keras.models.save_model(vgg_model,filepath='./weights/vgg')\n",
        "except Exception as e:\n",
        "    print(f'Failed to save weights')\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "vgg_loaded_model = tf.keras.models.load_model('./weights/vgg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "107/107 [==============================] - 1219s 11s/step - loss: 0.3276 - accuracy: 0.8813 - val_loss: 0.9861 - val_accuracy: 0.7121\n",
            "Epoch 2/50\n",
            "107/107 [==============================] - 1206s 11s/step - loss: 0.2350 - accuracy: 0.9088 - val_loss: 1.8934 - val_accuracy: 0.6049\n",
            "Epoch 3/50\n",
            "107/107 [==============================] - 1195s 11s/step - loss: 0.1659 - accuracy: 0.9398 - val_loss: 1.1993 - val_accuracy: 0.6875\n",
            "Epoch 4/50\n",
            "107/107 [==============================] - 1193s 11s/step - loss: 0.1291 - accuracy: 0.9565 - val_loss: 1.0578 - val_accuracy: 0.7299\n",
            "Epoch 5/50\n",
            "107/107 [==============================] - 1195s 11s/step - loss: 0.1067 - accuracy: 0.9630 - val_loss: 1.2136 - val_accuracy: 0.7299\n",
            "Epoch 6/50\n",
            "107/107 [==============================] - 1161s 11s/step - loss: 0.0699 - accuracy: 0.9756 - val_loss: 1.2341 - val_accuracy: 0.7545\n",
            "Epoch 7/50\n",
            "107/107 [==============================] - 1181s 11s/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 1.4392 - val_accuracy: 0.7009\n",
            "Epoch 8/50\n",
            "107/107 [==============================] - 1195s 11s/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 1.1653 - val_accuracy: 0.7545\n",
            "Epoch 9/50\n",
            "107/107 [==============================] - 1185s 11s/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 1.1292 - val_accuracy: 0.7746\n",
            "Epoch 10/50\n",
            "107/107 [==============================] - 1184s 11s/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.5363 - val_accuracy: 0.7254\n",
            "Epoch 11/50\n",
            "107/107 [==============================] - 1183s 11s/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.9874 - val_accuracy: 0.8080\n",
            "Epoch 12/50\n",
            "107/107 [==============================] - 1115s 10s/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 1.2559 - val_accuracy: 0.7478\n",
            "Epoch 13/50\n",
            "107/107 [==============================] - 1011s 9s/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.5656 - val_accuracy: 0.7857\n",
            "Epoch 14/50\n",
            "107/107 [==============================] - 1018s 10s/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.9886 - val_accuracy: 0.7679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg2/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg2/assets\n"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
        "vgg_model.trainable = True\n",
        "vgg_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "            # ,\n",
        "            # ModelCheckpoint(filepath='Fullmodel.{epoch:02d}-{acc:.2f}.h5', monitor='val_acc', save_best_only=False, mode='max')\n",
        "            ]\n",
        "\n",
        "history_vgg = vgg_model.fit(\n",
        "    train_generator, \n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "try:\n",
        "    tf.keras.models.save_model(vgg_model,filepath='./weights/vgg2')\n",
        "except Exception as e:\n",
        "    print(f'Failed to save weights')\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "107/107 [==============================] - 1012s 9s/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 1.5552 - val_accuracy: 0.7991\n",
            "Epoch 2/50\n",
            "107/107 [==============================] - 1009s 9s/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.0885 - val_accuracy: 0.7679\n",
            "Epoch 3/50\n",
            "107/107 [==============================] - 1025s 10s/step - loss: 8.1467e-04 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.8058\n",
            "Epoch 4/50\n",
            "107/107 [==============================] - 1004s 9s/step - loss: 9.7375e-05 - accuracy: 1.0000 - val_loss: 1.7744 - val_accuracy: 0.7946\n",
            "Epoch 5/50\n",
            "107/107 [==============================] - 1006s 9s/step - loss: 6.3233e-05 - accuracy: 1.0000 - val_loss: 1.6760 - val_accuracy: 0.8125\n",
            "Epoch 6/50\n",
            "107/107 [==============================] - 1004s 9s/step - loss: 2.4826e-05 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.8080\n",
            "Epoch 7/50\n",
            "107/107 [==============================] - 1019s 10s/step - loss: 1.8902e-05 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.8125\n",
            "Epoch 8/50\n",
            "107/107 [==============================] - 1035s 10s/step - loss: 1.4975e-05 - accuracy: 1.0000 - val_loss: 1.7527 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg3/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./weights/vgg3/assets\n"
          ]
        }
      ],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "vgg_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "            # ,\n",
        "            # ModelCheckpoint(filepath='Fullmodel.{epoch:02d}-{acc:.2f}.h5', monitor='val_acc', save_best_only=False, mode='max')]\n",
        "            ]\n",
        "\n",
        "history_vgg = vgg_model.fit(\n",
        "    train_generator, \n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "try:\n",
        "    tf.keras.models.save_model(vgg_model,filepath='./weights/vgg3')\n",
        "except Exception as e:\n",
        "    print(f'Failed to save weights')\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history_vgg' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\stavr\\AndroidStudioProjects\\CatchMeGame\\BirdsAppFinalProject\\Backend\\BirdsAlgorithm.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stavr/AndroidStudioProjects/CatchMeGame/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000038?line=0'>1</a>\u001b[0m acc \u001b[39m=\u001b[39m history_vgg\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stavr/AndroidStudioProjects/CatchMeGame/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000038?line=1'>2</a>\u001b[0m val_acc \u001b[39m=\u001b[39m history_vgg\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stavr/AndroidStudioProjects/CatchMeGame/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000038?line=2'>3</a>\u001b[0m loss \u001b[39m=\u001b[39m history_vgg\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history_vgg' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "acc = history_vgg.history['accuracy']\n",
        "val_acc = history_vgg.history['val_accuracy']\n",
        "loss = history_vgg.history['loss']\n",
        "val_loss = history_vgg.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 889 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_generator = test.flow_from_directory(\n",
        "        PATH_TEST,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-16 06:26:10.448392: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 822083584 exceeds 10% of free system memory.\n",
            "2022-07-16 06:26:10.723291: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 822083584 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/14 [=>............................] - ETA: 1:26 - loss: 148.7773 - accuracy: 0.7812"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-16 06:26:15.428684: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 822083584 exceeds 10% of free system memory.\n",
            "2022-07-16 06:26:15.674111: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 822083584 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2/14 [===>..........................] - ETA: 51s - loss: 143.4861 - accuracy: 0.7891 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-16 06:26:19.695227: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 822083584 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 61s 4s/step - loss: 151.6234 - accuracy: 0.7593\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[151.6234130859375, 0.7592800855636597]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vgg_model.evaluate(test_generator,use_multiprocessing=True,workers=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MobileNet V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"MobilenetV3small\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " Conv (Conv2D)                  (None, 112, 112, 16  432         ['rescaling[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv/BatchNorm (BatchNormaliza  (None, 112, 112, 16  64         ['Conv[0][0]']                   \n",
            " tion)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 112, 112, 16  0          ['Conv/BatchNorm[0][0]']         \n",
            " da)                            )                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 112, 112, 16  0           ['tf.__operators__.add[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 112, 112, 16  0           ['re_lu[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 112, 112, 16  0           ['Conv/BatchNorm[0][0]',         \n",
            "                                )                                 'tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise/pad (Z  (None, 113, 113, 16  0          ['multiply[0][0]']               \n",
            " eroPadding2D)                  )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise (Depth  (None, 56, 56, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
            " wiseConv2D)                                                     0]']                             \n",
            "                                                                                                  \n",
            " expanded_conv/depthwise/BatchN  (None, 56, 56, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 56, 56, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_1[0][0]']                \n",
            " vgPool (GlobalAveragePooling2D                                                                   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
            " onv (Conv2D)                                                    gPool[0][0]']                    \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
            " elu (ReLU)                                                      nv[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
            " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
            " mbda)                                                           nv_1[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 1, 1, 16)     0           ['tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, 1, 1, 16)    0           ['re_lu_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv/squeeze_excite/M  (None, 56, 56, 16)  0           ['re_lu_1[0][0]',                \n",
            " ul (Multiply)                                                    'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv/project (Conv2D)  (None, 56, 56, 16)  256         ['expanded_conv/squeeze_excite/Mu\n",
            "                                                                 l[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv/project/BatchNor  (None, 56, 56, 16)  64          ['expanded_conv/project[0][0]']  \n",
            " m (BatchNormalization)                                                                           \n",
            "                                                                                                  \n",
            " expanded_conv_1/expand (Conv2D  (None, 56, 56, 72)  1152        ['expanded_conv/project/BatchNorm\n",
            " )                                                               [0][0]']                         \n",
            "                                                                                                  \n",
            " expanded_conv_1/expand/BatchNo  (None, 56, 56, 72)  288         ['expanded_conv_1/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 56, 56, 72)   0           ['expanded_conv_1/expand/BatchNor\n",
            "                                                                 m[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise/pad   (None, 57, 57, 72)  0           ['re_lu_3[0][0]']                \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise (Dep  (None, 28, 28, 72)  648         ['expanded_conv_1/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_1/depthwise/Batc  (None, 28, 28, 72)  288         ['expanded_conv_1/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 28, 28, 72)   0           ['expanded_conv_1/depthwise/Batch\n",
            "                                                                 Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_1/project (Conv2  (None, 28, 28, 24)  1728        ['re_lu_4[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_1/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_1/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_2/expand (Conv2D  (None, 28, 28, 88)  2112        ['expanded_conv_1/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_2/expand/BatchNo  (None, 28, 28, 88)  352         ['expanded_conv_2/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 28, 28, 88)   0           ['expanded_conv_2/expand/BatchNor\n",
            "                                                                 m[0][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_2/depthwise (Dep  (None, 28, 28, 88)  792         ['re_lu_5[0][0]']                \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_2/depthwise/Batc  (None, 28, 28, 88)  352         ['expanded_conv_2/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 28, 28, 88)   0           ['expanded_conv_2/depthwise/Batch\n",
            "                                                                 Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_2/project (Conv2  (None, 28, 28, 24)  2112        ['re_lu_6[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_2/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_2/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_2/Add (Add)      (None, 28, 28, 24)   0           ['expanded_conv_1/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_2/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_3/expand (Conv2D  (None, 28, 28, 96)  2304        ['expanded_conv_2/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_3/expand/BatchNo  (None, 28, 28, 96)  384         ['expanded_conv_3/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 28, 28, 96)  0           ['expanded_conv_3/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 28, 28, 96)   0           ['tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, 28, 28, 96)  0           ['re_lu_7[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 28, 28, 96)   0           ['expanded_conv_3/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_2[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise/pad   (None, 31, 31, 96)  0           ['multiply_1[0][0]']             \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise (Dep  (None, 14, 14, 96)  2400        ['expanded_conv_3/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_3/depthwise/Batc  (None, 14, 14, 96)  384         ['expanded_conv_3/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 14, 14, 96)  0           ['expanded_conv_3/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 14, 14, 96)   0           ['tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 14, 14, 96)  0           ['re_lu_8[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 14, 14, 96)   0           ['expanded_conv_3/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_2[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_3/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_3/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_3/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 1, 1, 96)    0           ['expanded_conv_3/squeeze_excite/\n",
            " mbda)                                                           Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 1, 1, 96)     0           ['tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (None, 1, 1, 96)    0           ['re_lu_9[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_3/squeeze_excite  (None, 14, 14, 96)  0           ['multiply_2[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_4[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_3/project (Conv2  (None, 14, 14, 40)  3840        ['expanded_conv_3/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_3/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_3/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_4/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_3/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_4/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_4/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_4/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_10[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_4/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_3[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_4/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_4/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_4/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_11[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_4/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_6[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_4[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_4/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_4/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_4/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 1, 1, 240)   0           ['expanded_conv_4/squeeze_excite/\n",
            " mbda)                                                           Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 1, 1, 240)   0           ['re_lu_12[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_4/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_4[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_7[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_4/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_4/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_4/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_4/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_4/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_3/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_4/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_5/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_4/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_5/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_5/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_5/expand/BatchNor\n",
            " mbda)                                                           m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_13[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_5/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_5/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_5[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_5/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_5/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_5/depthwise/Batch\n",
            " mbda)                                                           Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_14[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_5/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_9[0][0]']     \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_6[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_5/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_5/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_5/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_5/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_10[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_15[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_5/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_6[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_10[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_5/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_5/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_5/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_5/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_5/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_4/Add[0][0]',    \n",
            "                                                                  'expanded_conv_5/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_6/expand (Conv2D  (None, 14, 14, 120)  4800       ['expanded_conv_5/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_6/expand/BatchNo  (None, 14, 14, 120)  480        ['expanded_conv_6/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_11[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_16[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 14, 14, 120)  0           ['expanded_conv_6/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/depthwise (Dep  (None, 14, 14, 120)  3000       ['multiply_7[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_6/depthwise/Batc  (None, 14, 14, 120)  480        ['expanded_conv_6/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_12[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_17[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 14, 14, 120)  0           ['expanded_conv_6/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_12[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   0           ['multiply_8[0][0]']             \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    3872        ['expanded_conv_6/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    0           ['expanded_conv_6/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   3960        ['expanded_conv_6/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_13 (TFOpL  (None, 1, 1, 120)   0           ['expanded_conv_6/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 1, 1, 120)    0           ['tf.__operators__.add_13[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 1, 1, 120)   0           ['re_lu_18[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_6/squeeze_excite  (None, 14, 14, 120)  0          ['multiply_8[0][0]',             \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_6/project (Conv2  (None, 14, 14, 48)  5760        ['expanded_conv_6/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_6/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_6/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_7/expand (Conv2D  (None, 14, 14, 144)  6912       ['expanded_conv_6/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_7/expand/BatchNo  (None, 14, 14, 144)  576        ['expanded_conv_7/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_14 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_14[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_14 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_19[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 14, 14, 144)  0           ['expanded_conv_7/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_14[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/depthwise (Dep  (None, 14, 14, 144)  3600       ['multiply_9[0][0]']             \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_7/depthwise/Batc  (None, 14, 14, 144)  576        ['expanded_conv_7/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_15 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_15[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_15 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_20[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 14, 14, 144)  0           ['expanded_conv_7/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_15[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   0           ['multiply_10[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    5800        ['expanded_conv_7/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    0           ['expanded_conv_7/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   5904        ['expanded_conv_7/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_16 (TFOpL  (None, 1, 1, 144)   0           ['expanded_conv_7/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 1, 1, 144)    0           ['tf.__operators__.add_16[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_16 (TFOpLambd  (None, 1, 1, 144)   0           ['re_lu_21[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_7/squeeze_excite  (None, 14, 14, 144)  0          ['multiply_10[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_16[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_7/project (Conv2  (None, 14, 14, 48)  6912        ['expanded_conv_7/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_7/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_7/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_7/Add (Add)      (None, 14, 14, 48)   0           ['expanded_conv_6/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_7/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_8/expand (Conv2D  (None, 14, 14, 288)  13824      ['expanded_conv_7/Add[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_8/expand/BatchNo  (None, 14, 14, 288)  1152       ['expanded_conv_8/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_17 (TFOpL  (None, 14, 14, 288)  0          ['expanded_conv_8/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 14, 14, 288)  0           ['tf.__operators__.add_17[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_17 (TFOpLambd  (None, 14, 14, 288)  0          ['re_lu_22[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 14, 14, 288)  0           ['expanded_conv_8/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_17[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise/pad   (None, 17, 17, 288)  0          ['multiply_11[0][0]']            \n",
            " (ZeroPadding2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise (Dep  (None, 7, 7, 288)   7200        ['expanded_conv_8/depthwise/pad[0\n",
            " thwiseConv2D)                                                   ][0]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_8/depthwise/Batc  (None, 7, 7, 288)   1152        ['expanded_conv_8/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_18 (TFOpL  (None, 7, 7, 288)   0           ['expanded_conv_8/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 7, 7, 288)    0           ['tf.__operators__.add_18[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_18 (TFOpLambd  (None, 7, 7, 288)   0           ['re_lu_23[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 7, 7, 288)    0           ['expanded_conv_8/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_18[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   0           ['multiply_12[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    20808       ['expanded_conv_8/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    0           ['expanded_conv_8/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   21024       ['expanded_conv_8/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_19 (TFOpL  (None, 1, 1, 288)   0           ['expanded_conv_8/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 1, 1, 288)    0           ['tf.__operators__.add_19[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_19 (TFOpLambd  (None, 1, 1, 288)   0           ['re_lu_24[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_8/squeeze_excite  (None, 7, 7, 288)   0           ['multiply_12[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_19[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_8/project (Conv2  (None, 7, 7, 96)    27648       ['expanded_conv_8/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_8/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_8/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_9/expand (Conv2D  (None, 7, 7, 576)   55296       ['expanded_conv_8/project/BatchNo\n",
            " )                                                               rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_9/expand/BatchNo  (None, 7, 7, 576)   2304        ['expanded_conv_9/expand[0][0]'] \n",
            " rm (BatchNormalization)                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/expand/BatchNor\n",
            " ambda)                                                          m[0][0]']                        \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_20[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_25[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/expand/BatchNor\n",
            "                                                                 m[0][0]',                        \n",
            "                                                                  'tf.math.multiply_20[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/depthwise (Dep  (None, 7, 7, 576)   14400       ['multiply_13[0][0]']            \n",
            " thwiseConv2D)                                                                                    \n",
            "                                                                                                  \n",
            " expanded_conv_9/depthwise/Batc  (None, 7, 7, 576)   2304        ['expanded_conv_9/depthwise[0][0]\n",
            " hNorm (BatchNormalization)                                      ']                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_21 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/depthwise/Batch\n",
            " ambda)                                                          Norm[0][0]']                     \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_21[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_26[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/depthwise/Batch\n",
            "                                                                 Norm[0][0]',                     \n",
            "                                                                  'tf.math.multiply_21[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   0           ['multiply_14[0][0]']            \n",
            " /AvgPool (GlobalAveragePooling                                                                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   83088       ['expanded_conv_9/squeeze_excite/\n",
            " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   0           ['expanded_conv_9/squeeze_excite/\n",
            " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   83520       ['expanded_conv_9/squeeze_excite/\n",
            " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_22 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_9/squeeze_excite/\n",
            " ambda)                                                          Conv_1[0][0]']                   \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_22[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_27[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_9/squeeze_excite  (None, 7, 7, 576)   0           ['multiply_14[0][0]',            \n",
            " /Mul (Multiply)                                                  'tf.math.multiply_22[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_9/project (Conv2  (None, 7, 7, 96)    55296       ['expanded_conv_9/squeeze_excite/\n",
            " D)                                                              Mul[0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_9/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_9/project[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " expanded_conv_9/Add (Add)      (None, 7, 7, 96)     0           ['expanded_conv_8/project/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'expanded_conv_9/project/BatchNo\n",
            "                                                                 rm[0][0]']                       \n",
            "                                                                                                  \n",
            " expanded_conv_10/expand (Conv2  (None, 7, 7, 576)   55296       ['expanded_conv_9/Add[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_10/expand/BatchN  (None, 7, 7, 576)   2304        ['expanded_conv_10/expand[0][0]']\n",
            " orm (BatchNormalization)                                                                         \n",
            "                                                                                                  \n",
            " tf.__operators__.add_23 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/expand/BatchNo\n",
            " ambda)                                                          rm[0][0]']                       \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_23[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_28[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/expand/BatchNo\n",
            "                                                                 rm[0][0]',                       \n",
            "                                                                  'tf.math.multiply_23[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/depthwise (De  (None, 7, 7, 576)   14400       ['multiply_15[0][0]']            \n",
            " pthwiseConv2D)                                                                                   \n",
            "                                                                                                  \n",
            " expanded_conv_10/depthwise/Bat  (None, 7, 7, 576)   2304        ['expanded_conv_10/depthwise[0][0\n",
            " chNorm (BatchNormalization)                                     ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_24 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/depthwise/Batc\n",
            " ambda)                                                          hNorm[0][0]']                    \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_24[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_24 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_29[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/depthwise/Batc\n",
            "                                                                 hNorm[0][0]',                    \n",
            "                                                                  'tf.math.multiply_24[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   0           ['multiply_16[0][0]']            \n",
            " e/AvgPool (GlobalAveragePoolin                                                                   \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   83088       ['expanded_conv_10/squeeze_excite\n",
            " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   0           ['expanded_conv_10/squeeze_excite\n",
            " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   83520       ['expanded_conv_10/squeeze_excite\n",
            " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_25 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_10/squeeze_excite\n",
            " ambda)                                                          /Conv_1[0][0]']                  \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_25[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_25 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_30[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " expanded_conv_10/squeeze_excit  (None, 7, 7, 576)   0           ['multiply_16[0][0]',            \n",
            " e/Mul (Multiply)                                                 'tf.math.multiply_25[0][0]']    \n",
            "                                                                                                  \n",
            " expanded_conv_10/project (Conv  (None, 7, 7, 96)    55296       ['expanded_conv_10/squeeze_excite\n",
            " 2D)                                                             /Mul[0][0]']                     \n",
            "                                                                                                  \n",
            " expanded_conv_10/project/Batch  (None, 7, 7, 96)    384         ['expanded_conv_10/project[0][0]'\n",
            " Norm (BatchNormalization)                                       ]                                \n",
            "                                                                                                  \n",
            " expanded_conv_10/Add (Add)     (None, 7, 7, 96)     0           ['expanded_conv_9/Add[0][0]',    \n",
            "                                                                  'expanded_conv_10/project/BatchN\n",
            "                                                                 orm[0][0]']                      \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 576)    55296       ['expanded_conv_10/Add[0][0]']   \n",
            "                                                                                                  \n",
            " Conv_1/BatchNorm (BatchNormali  (None, 7, 7, 576)   2304        ['Conv_1[0][0]']                 \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_26 (TFOpL  (None, 7, 7, 576)   0           ['Conv_1/BatchNorm[0][0]']       \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_26[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.multiply_26 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_31[0][0]']               \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 7, 7, 576)    0           ['Conv_1/BatchNorm[0][0]',       \n",
            "                                                                  'tf.math.multiply_26[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 939,120\n",
            "Trainable params: 0\n",
            "Non-trainable params: 939,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = keras.applications.MobileNetV3Small(input_shape=(224, 224, 3),\n",
        "                                            classes=len(birds_names_DB),\n",
        "                                            include_top=False,\n",
        "                                            weights='imagenet')\n",
        "\n",
        "# Freeze convolutional base\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 576)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3462      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 942,582\n",
            "Trainable params: 3,462\n",
            "Non-trainable params: 939,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.models.Sequential([\n",
        "    keras.layers.RandomFlip('horizontal'),\n",
        "    keras.layers.RandomRotation(0.2)\n",
        "])\n",
        "num_classes = len(birds_names_DB)# 7\n",
        "\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "#x = data_augmentation(inputs)\n",
        "x = keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "mobile_model = keras.Model(inputs, outputs)\n",
        "mobile_model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "mobile_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: <class 'keras.preprocessing.image.ImageDataGenerator'>, <class 'NoneType'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1427/3913428602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history_mobileNet = mobile_model.fit(train_datagen, \n\u001b[0m\u001b[1;32m      4\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \"input: {}, {}\".format(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'keras.preprocessing.image.ImageDataGenerator'>, <class 'NoneType'>"
          ]
        }
      ],
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True)\n",
        "\n",
        "history_mobileNet = mobile_model.fit(train_datagen, \n",
        "                            validation_data=valid_datagen,\n",
        "                            epochs=150,\n",
        "                            callbacks=[early_stop])\n",
        "\n",
        "try:\n",
        "    mobile_model.save_model('./weights/mobile')\n",
        "except Exception as e:\n",
        "    print(f'Failed to save weights')\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history_mobileNet' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_654/2907839092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minitial_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_mobileNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_mobileNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_mobileNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history_mobileNet' is not defined"
          ]
        }
      ],
      "source": [
        "initial_epochs = len(history_mobileNet.history['accuracy'])\n",
        "\n",
        "acc = history_mobileNet.history['accuracy']\n",
        "val_acc = history_mobileNet.history['val_accuracy']\n",
        "\n",
        "loss = history_mobileNet.history['loss']\n",
        "val_loss = history_mobileNet.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLzSLwcvTX6y"
      },
      "source": [
        "### EfficientNetB0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXTIggb3baag",
        "outputId": "b02ccb5a-d599-487f-e15f-56d64164a9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3192 files belonging to 6 classes.\n",
            "Found 448 files belonging to 6 classes.\n",
            "Found 889 files belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE=(224,224)\n",
        "\n",
        "train_data=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH_TRAIN,\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE\n",
        ")\n",
        "class_names=train_data.class_names\n",
        "num_classes=len(class_names)\n",
        "val_data=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH_VAL,\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE,\n",
        "    \n",
        ")\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH_TEST,\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "train_data_pf=train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_data_pf=val_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_data_pf=test_data.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTbi-PMic5gA"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import layers,mixed_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T6b9r0IcC2-"
      },
      "source": [
        "#### EfficientB0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JMzx09UbaYQ"
      },
      "outputs": [],
      "source": [
        "#1 Define Data Augmentation Layer\n",
        "data_augmentation=keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.2,fill_mode='nearest'),\n",
        "    # layers.Rescaling(scale=1.0/255)\n",
        "],name='Data_Augmentation_Layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc9jIVDAbaWB"
      },
      "outputs": [],
      "source": [
        "#2 Create the model\n",
        "# import efficientnet.keras as efn \n",
        "\n",
        "mixed_precision.set_global_policy('float32')\n",
        "\n",
        "inputs=layers.Input(shape=(224,224,3), dtype='float32',name='input_layer')\n",
        "\n",
        "base_model = keras.applications.EfficientNetB0(weights='imagenet') \n",
        "\n",
        "# base_model.trainable=False\n",
        "\n",
        "x=data_augmentation(inputs)\n",
        "x=base_model(x,training=False)\n",
        "\n",
        "# x=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\n",
        "num_classes=len(train_data.class_names)\n",
        "outputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n",
        "\n",
        "model=keras.Model(inputs,outputs,name=\"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUitedl0capb",
        "outputId": "3383c0ea-2413-4195-e24e-23fffc99467b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " Data_Augmentation_Layer (Se  (None, 224, 224, 3)      0         \n",
            " quential)                                                       \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 1000)             5330571   \n",
            "                                                                 \n",
            " Output_layer (Dense)        (None, 6)                 6006      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,336,577\n",
            "Trainable params: 5,294,554\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#3 Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#4 model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0pp3QHfcf5o",
        "outputId": "96b3eb8c-54b8-433e-93b3-c7e786832587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 393s 15s/step - loss: 1.7804 - accuracy: 0.1842 - val_loss: 1.7787 - val_accuracy: 0.1875\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 373s 15s/step - loss: 1.7801 - accuracy: 0.1842 - val_loss: 1.7783 - val_accuracy: 0.1875\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 369s 15s/step - loss: 1.7798 - accuracy: 0.1842 - val_loss: 1.7781 - val_accuracy: 0.1875\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 366s 15s/step - loss: 1.7796 - accuracy: 0.1842 - val_loss: 1.7779 - val_accuracy: 0.1875\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7796 - accuracy: 0.1842 "
          ]
        }
      ],
      "source": [
        "#5 Fit the model\n",
        "history_of_model=model.fit(\n",
        "                                    train_generator,\n",
        "                                    epochs=100,\n",
        "                                    validation_data=valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YpKW5Kncj6f",
        "outputId": "e97f909e-f75c-4b68-a5b4-c324b76e340d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 24s 857ms/step - loss: 1.7806 - accuracy: 0.1811\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.7805765867233276, 0.18110236525535583]"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#6 model_0 result\n",
        "model_0_result=model.evaluate(test_data_pf)\n",
        "model_0_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1sEQvx6cp5H"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(history):\n",
        "    \n",
        "    '''\n",
        "      returns seperate loss curves for training and validation metrics\n",
        "    '''\n",
        "    train_loss=history.history['loss']\n",
        "    val_loss=history.history['val_loss']\n",
        "\n",
        "    train_accuracy=history.history['accuracy']\n",
        "    val_accuracy=history.history['val_accuracy']\n",
        "\n",
        "    epochs=range(1,len(history.history['loss'])+1)\n",
        "    plt.figure(figsize=(20,7))\n",
        "  # plot loss data\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs,train_loss,label=\"training_loss\")\n",
        "    plt.plot(epochs,val_loss,label=\"validation_loss\")\n",
        "    plt.title(\"Loss curves\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "  # plt.show()\n",
        "\n",
        "  # plot accuracy data\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs,train_accuracy,label=\"training_acc\")\n",
        "    plt.plot(epochs,val_accuracy,label=\"validation_acc\")\n",
        "    plt.title(\"Accuracy curves\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final model\n",
        "densenet201_final_model = tf.keras.Model(densenet201_raw_model.input, appended_layer)\n",
        "densenet201_final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "t_model = tf.keras.models.load_model('./weights/denseNet/')\n",
        "t_model.save('denseNet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working predict function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at ./vgg2.h5",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32md:\\BirdsAppFinalProject\\Backend\\BirdsAlgorithm.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000066?line=9'>10</a>\u001b[0m test_img_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../../Images/nabirds/images/Eurasian Collared-Dove/e4af5008760e4919b569a88f870ac279.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000066?line=10'>11</a>\u001b[0m \u001b[39m# Model choose and upload\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000066?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m./vgg2.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000066?line=12'>13</a>\u001b[0m \u001b[39m# Image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BirdsAppFinalProject/Backend/BirdsAlgorithm.ipynb#ch0000066?line=13'>14</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(test_img_path))\n",
            "File \u001b[1;32md:\\BirdsAppFinalProject\\Backend\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32md:\\BirdsAppFinalProject\\Backend\\env\\lib\\site-packages\\keras\\saving\\save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    205\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
            "\u001b[1;31mOSError\u001b[0m: No file or directory found at ./vgg2.h5"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from PIL import Image\n",
        "import  cv2\n",
        "\n",
        "bird_dict = ['American Pipit', 'Eurasian Collared-Dove', 'House Sparrow', 'European Starling', 'Gadwall', 'Rock Pigeon']\n",
        "size = (224, 224)\n",
        "#image\n",
        "test_img_path = '../../Images/nabirds/images/Eurasian Collared-Dove/e4af5008760e4919b569a88f870ac279.jpg'\n",
        "# Model choose and upload\n",
        "model = keras.models.load_model('./vgg2.h5')\n",
        "# Image\n",
        "img = np.array(Image.open(test_img_path))\n",
        "img = cv2.resize(img, size)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "# run model\n",
        "print(bird_dict[np.argmax(model.predict(img))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "81-X9OQPm5UD"
      ],
      "name": "Birds Algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c7fcc66a568c4b5db8cc4fb02a001b537d5b09631385473faa01d26c0b51a4f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
